# "千寻" 搜索

![search_engine](/statics/search_engine.png)

上图为一个搜索引擎的框架图。首先爬虫程序从特定的几个新闻网站抓取新闻数据，然后过滤网页中的图片、视频、广告等无关元素，抽取新闻的主体内容，得到结构化的xml数据。然后一方面使用内存式单遍扫描索引构建方法（SPIMI）构建倒排索引，供检索模型使用；另一方面根据向量空间模型计算两两新闻之间的余弦相似度，供推荐模块使用。最后利用概率检索模型中的BM25公式计算给定关键词下的文档相关性评分，BM25打分结合时间因素得到热度评分，根据评分给出排序结果。本实验根据此框架图构建搜索引擎项目。



1.1  网络爬虫

网络爬虫[1]（英语：web crawler），也叫网络蜘蛛（spider），是一种用来自动浏览万维网的网络机器人。其目的一般为编纂网络索引。

网络搜索引擎等站点通过爬虫软件更新自身的网站内容或其对其他网站的索引。网络爬虫可以将自己所访问的页面保存下来，以便搜索引擎事后生成索引供用户搜索。

大型网站几乎都有反爬虫策略，通常具有以下防反爬方法：设置随机User Agent、设置爬取间隔时间、带可用Cookie和使用代理。

在Python 3环境下，这里使用了BeatifulSoup4来对网页进行解析。

 

1.2  构建索引

倒排索引[2]（英语：Inverted index），也常被称为反向索引、置入档案或反向档案，是一种索引方法，被用来存储在全文搜索下某个单词在一个文档或者一组文档中的存储位置的映射。它是文档检索系统中最常用的数据结构。

![inverted_index](statics/inverted_index.png)

图2 倒排索引

 

上图是一个倒排索引模型，左边部分称为词典。通过借助目前比较流行的jieba中文分词组件来将中文句子切成一个个词项。在搜索中还要进行停用词的去除，如“的”、“地”、“得”等词实际上没有区分效果。因此在jieba分词结束后进行去停用词的操作。为了高效率地存储，我们采用上图所示的方式，词典部分用B树存储，倒排记录表用邻接链表存储，将倒排记录表序列化成长字符串写入到一个单元格，读取时再进行反序列化。

倒排索引构建算法使用内存式单遍扫描索引构建方法（SPIMI），其实就是依次对每篇新闻进行分词，如果出现新的词项则插入到词典中，否则将该文档的信息追加到词项对应的倒排记录表中。SPIMI的伪代码如下：

![spimi](statics/spimi.png)

 

1.3  系统展示

 

 

[1] 网络爬虫 – 维基百科，自由的百科全书

<https://zh.wikipedia.org/zh-cn/%E7%B6%B2%E8%B7%AF%E7%88%AC%E8%9F%B2>

 

[2] 倒排索引 – 维基百科，自由的百科全书

https://zh.wikipedia.org/wiki/%E5%80%92%E6%8E%92%E7%B4%A2%E5%BC%95

 